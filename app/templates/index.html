<!doctype html>
<html class="bg-gray-900">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>SPOC-Shot Demo</title>
  <script>
    // Capture navigator.gpu BEFORE any other scripts can interfere
    window._originalGPU = navigator.gpu;
    console.log("üîß Captured original navigator.gpu:", window._originalGPU);
  </script>
  <script src="https://unpkg.com/htmx.org@1.9.10"></script>
  <script src="https://cdn.tailwindcss.com"></script>
  <!-- Remove the early import - we'll do dynamic import in the function -->
  <style>
    /* Reset and base styles */
    * {
      box-sizing: border-box;
    }
    
    html, body {
      margin: 0;
      padding: 0;
      overflow-x: hidden; /* Prevent horizontal scroll */
    }
    
    /* Custom styles for the toggle switch */
    .toggle-checkbox:checked {
      right: 0;
      border-color: #4A5568;
    }
    .toggle-checkbox:checked + .toggle-label {
      background-color: #4A5568;
    }
    
    /* Simple fade-in animation for log entries */
    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(10px); }
      to { opacity: 1; transform: translateY(0); }
    }
    .log-entry {
      animation: fadeIn 0.3s ease-out;
    }
    
    /* Ensure proper spacing and prevent overflow */
    .main-container {
      max-width: 100%;
      overflow-x: hidden;
    }
    
    /* Responsive grid improvements */
    @media (max-width: 1024px) {
      .grid.lg\\:grid-cols-2 {
        grid-template-columns: 1fr !important;
        gap: 1.5rem;
      }
    }
    
  </style>
</head>
<body class="min-h-full bg-gray-900 text-white font-sans p-4 sm:p-6 lg:p-8">

  <div class="main-container w-full max-w-7xl mx-auto">
    <header class="text-center mb-8 py-6">
      <h1 class="text-4xl sm:text-5xl font-bold text-white">SPOC-Shot</h1>
      <p class="text-gray-400 mt-2">A Live Demo of Single-Pass Self-Correcting Agent Loops</p>
    </header>

    <!-- Model Loading Overlay (initially hidden) -->
    <div id="model-loading-panel" class="fixed inset-0 bg-black/50 flex items-center justify-center z-50" style="display: none;">
      <div class="bg-gray-800 border border-blue-700 p-8 rounded-lg shadow-2xl max-w-md w-full mx-4">
        <h2 class="text-xl font-semibold mb-4 flex items-center text-center">
          <span class="mr-2">üß†</span> Initializing WebLLM
        </h2>
        <div class="mb-6">
          <div class="flex justify-between text-sm text-gray-300 mb-2">
            <span id="model-status">Starting WebLLM initialization...</span>
            <span id="model-progress-text">0%</span>
          </div>
          <div class="w-full bg-gray-700 rounded-full h-3">
            <div id="model-progress-bar" class="bg-blue-600 h-3 rounded-full transition-all duration-300" style="width: 0%"></div>
          </div>
        </div>
        <p class="text-sm text-gray-400 text-center">
          Loading Qwen3-0.6B (~300MB)<br>
          <span class="text-xs text-gray-500">This happens once and caches locally</span>
        </p>
      </div>
    </div>

    <div class="grid grid-cols-1 lg:grid-cols-2 gap-6 mb-8">
      <!-- Left Column -->
      <div class="flex flex-col gap-6">
        <!-- Controls Panel -->
        <div class="bg-gray-800 p-6 rounded-lg shadow-2xl">
          <h2 class="text-xl font-semibold mb-4">Agent Configuration</h2>
          <form id="prompt-form"
                hx-post="/solve"
                hx-trigger="submit"
                hx-ext="sse"
                hx-swap="none">
            <div class="mb-4">
              <label for="scenario-select" class="block text-sm font-medium text-gray-300 mb-2">Agent Scenario</label>
              <select id="scenario-select" name="scenario" class="w-full bg-gray-700 border border-gray-600 rounded-md p-3 focus:outline-none focus:ring-2 focus:ring-blue-500">
                <option value="sql" selected>üóÉÔ∏è SQL Query Agent</option>
                <option value="research">üîç Research Agent</option>
                <option value="data_analysis">üìä Data Analyst</option>
                <option value="math_tutor">üßÆ Math Tutor</option>
              </select>
            </div>
            <div class="mb-4">
              <label for="agent-mode" class="block text-sm font-medium text-gray-300 mb-2">Agent Mode</label>
              <div class="relative inline-block w-full text-sm">
                  <select id="agent-mode" name="mode" class="w-full bg-gray-700 border border-gray-600 rounded-md p-3 focus:outline-none focus:ring-2 focus:ring-blue-500">
                      <option value="multi_pass" selected>Multi-Pass (Baseline)</option>
                      <option value="single_pass">Single-Pass (SPOC)</option>
                  </select>
              </div>
            </div>
            <div class="mb-4">
              <label for="complexity-slider" class="block text-sm font-medium text-gray-300 mb-2">Complexity Level: <span id="complexity-value">3</span></label>
              <input type="range" id="complexity-slider" min="1" max="5" value="3" class="w-full bg-gray-700 rounded-lg appearance-none cursor-pointer">
              <div class="flex justify-between text-xs text-gray-400 mt-1">
                <span>Simple</span>
                <span>Complex</span>
              </div>
            </div>
            <div class="mb-4">
              <label for="prompt-input" class="block text-sm font-medium text-gray-300 mb-2">Prompt</label>
              <textarea id="prompt-input" name="prompt" rows="3" class="w-full bg-gray-700 border border-gray-600 rounded-md p-3 focus:outline-none focus:ring-2 focus:ring-blue-500" placeholder="Enter your prompt here...">How many conversions did we get this week?</textarea>
            </div>
            <div class="flex gap-2">
              <button id="run-button" type="submit" class="flex-1 bg-blue-600 hover:bg-blue-700 text-white font-bold py-3 px-4 rounded-md transition-colors disabled:bg-gray-500">
                Run Agent
              </button>
              <button id="race-button" type="button" class="bg-orange-600 hover:bg-orange-700 text-white font-bold py-3 px-4 rounded-md transition-colors disabled:bg-gray-500">
                üèÅ Race
              </button>
            </div>
          </form>
        </div>

        <!-- Enhanced Metrics Panel -->
        <div class="bg-gray-800 p-6 rounded-lg shadow-2xl">
          <h2 class="text-xl font-semibold mb-4">Real-Time Performance</h2>
          
          <!-- Token Burn Meter -->
          <div class="mb-6">
            <div class="flex justify-between items-center mb-2">
              <span class="text-sm font-medium text-gray-300">Token Burn Rate</span>
              <span id="burn-rate" class="text-sm text-orange-400">0 tok/s</span>
            </div>
            <div class="w-full bg-gray-700 rounded-full h-3 relative overflow-hidden">
              <div id="token-burn-bar" class="h-3 rounded-full transition-all duration-300 bg-gradient-to-r from-orange-500 to-red-500" style="width: 0%"></div>
              <div class="absolute inset-0 flex items-center justify-center text-xs font-bold text-white">
                <span id="total-tokens">0 tokens</span>
              </div>
            </div>
          </div>

          <!-- Memory Visualization -->
          <div class="mb-6">
            <div class="flex justify-between items-center mb-2">
              <span class="text-sm font-medium text-gray-300">Context Memory</span>
              <span id="memory-efficiency" class="text-sm text-blue-400">100% retained</span>
            </div>
            <div class="grid grid-cols-10 gap-1 h-4">
              <div id="memory-blocks" class="contents">
                <!-- Memory blocks will be generated here -->
              </div>
            </div>
            <div class="flex justify-between text-xs text-gray-500 mt-1">
              <span>Fresh</span>
              <span>Cached</span>
            </div>
          </div>

          <!-- Cost Calculator -->
          <div class="mb-6 p-3 bg-gray-900/50 rounded-lg">
            <div class="flex justify-between items-center mb-2">
              <span class="text-sm font-medium text-gray-300">üí∞ Cost Analysis</span>
              <span id="cost-per-run" class="text-sm text-green-400">$0.000</span>
            </div>
            <div class="grid grid-cols-2 gap-4 text-xs">
              <div>
                <div class="text-gray-400">Per 1K runs:</div>
                <div id="cost-1k" class="font-bold text-green-300">$0.00</div>
              </div>
              <div>
                <div class="text-gray-400">Monthly (10K):</div>
                <div id="cost-monthly" class="font-bold text-blue-300">$0.00</div>
              </div>
            </div>
          </div>

          <!-- Core Metrics -->
          <div class="grid grid-cols-2 gap-4 text-center">
            <div>
              <p class="text-gray-400 text-sm">Latency</p>
              <p id="metric-latency" class="text-2xl font-bold">0.00s</p>
            </div>
            <div>
              <p class="text-gray-400 text-sm">LLM Calls</p>
              <p id="metric-llm-calls" class="text-2xl font-bold">0</p>
            </div>
            <div>
              <p class="text-gray-400 text-sm">Input Tokens</p>
              <p id="metric-prompt-tokens" class="text-xl font-bold">0</p>
            </div>
            <div>
              <p class="text-gray-400 text-sm">Output Tokens</p>
              <p id="metric-completion-tokens" class="text-xl font-bold">0</p>
            </div>
          </div>
        </div>
      </div>

      <!-- Right Column -->
      <div class="flex flex-col gap-6">
        <!-- Code View Panel -->
        <div class="bg-gray-800 p-6 rounded-lg shadow-2xl">
          <h2 class="text-xl font-semibold mb-4">Agent Logic</h2>
          <div id="code-view" class="bg-gray-900 p-4 rounded-md text-xs font-mono">
            <!-- Pseudo-code will be injected here -->
          </div>
        </div>

        <!-- Live Execution Details -->
        <div class="bg-gray-800 p-6 rounded-lg shadow-2xl">
          <h2 class="text-xl font-semibold mb-4">üîç Execution Details</h2>
          <div class="grid grid-cols-2 gap-4 text-sm">
            <div>
              <div class="text-gray-400 mb-2">Current Phase</div>
              <div id="current-phase" class="font-mono text-cyan-400">Ready</div>
            </div>
            <div>
              <div class="text-gray-400 mb-2">Last Tool Call</div>
              <div id="last-tool" class="font-mono text-purple-400">None</div>
            </div>
            <div>
              <div class="text-gray-400 mb-2">Context Size</div>
              <div id="context-size" class="font-mono text-blue-400">0 tokens</div>
            </div>
            <div>
              <div class="text-gray-400 mb-2">Efficiency</div>
              <div id="efficiency-ratio" class="font-mono text-green-400">--</div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Log Stream Panel -->
    <div id="log-panel" class="mt-8 bg-gray-800 p-6 rounded-lg shadow-2xl">
      <h2 class="text-xl font-semibold mb-4">üîÑ Live Agent Execution</h2>
      <div id="log-container" class="h-96 overflow-y-auto bg-gray-900 p-4 rounded-md">
        <div id="log" class="space-y-2 text-sm font-mono">
          <div class="text-gray-500">Run an agent to see live execution details...</div>
        </div>
      </div>
    </div>

    <!-- Racing Panel (hidden by default) -->
    <div id="racing-panel" class="mt-8 bg-gray-800 p-6 rounded-lg shadow-2xl" style="display: none;">
      <h2 class="text-xl font-semibold mb-4 flex items-center">
        üèÅ Agent Racing Arena
        <button id="stop-race" class="ml-4 bg-red-600 hover:bg-red-700 text-white px-3 py-1 rounded text-sm" style="display: none;">Stop Race</button>
        <button id="close-race" class="ml-auto text-gray-400 hover:text-white">‚úï</button>
      </h2>
      <div class="grid grid-cols-1 lg:grid-cols-2 gap-6">
        <!-- Multi-Pass Lane -->
        <div class="bg-red-900/20 border border-red-700 p-4 rounded-lg">
          <h3 class="text-lg font-semibold text-red-300 mb-3 flex items-center">
            üêå Multi-Pass Agent
            <span id="multi-pass-status" class="ml-auto text-sm px-2 py-1 bg-gray-700 rounded">Ready</span>
          </h3>
          <div class="mb-3">
            <div class="flex justify-between text-sm text-gray-300 mb-1">
              <span>Progress</span>
              <span id="multi-pass-progress-text">0%</span>
            </div>
            <div class="w-full bg-gray-700 rounded-full h-2">
              <div id="multi-pass-progress" class="bg-red-500 h-2 rounded-full transition-all duration-500" style="width: 0%"></div>
            </div>
          </div>
          <div id="multi-pass-log" class="h-48 overflow-y-auto bg-gray-900/50 p-3 rounded text-xs font-mono">
            <div class="text-gray-500">Waiting to start...</div>
          </div>
          <div class="mt-3 grid grid-cols-3 gap-2 text-center text-xs">
            <div>
              <div class="text-gray-400">Time</div>
              <div id="multi-pass-time" class="font-bold">--</div>
            </div>
            <div>
              <div class="text-gray-400">Tokens</div>
              <div id="multi-pass-tokens" class="font-bold">--</div>
            </div>
            <div>
              <div class="text-gray-400">Calls</div>
              <div id="multi-pass-calls" class="font-bold">--</div>
            </div>
          </div>
        </div>

        <!-- Single-Pass Lane -->
        <div class="bg-green-900/20 border border-green-700 p-4 rounded-lg">
          <h3 class="text-lg font-semibold text-green-300 mb-3 flex items-center">
            üöÄ Single-Pass Agent
            <span id="single-pass-status" class="ml-auto text-sm px-2 py-1 bg-gray-700 rounded">Ready</span>
          </h3>
          <div class="mb-3">
            <div class="flex justify-between text-sm text-gray-300 mb-1">
              <span>Progress</span>
              <span id="single-pass-progress-text">0%</span>
            </div>
            <div class="w-full bg-gray-700 rounded-full h-2">
              <div id="single-pass-progress" class="bg-green-500 h-2 rounded-full transition-all duration-500" style="width: 0%"></div>
            </div>
          </div>
          <div id="single-pass-log" class="h-48 overflow-y-auto bg-gray-900/50 p-3 rounded text-xs font-mono">
            <div class="text-gray-500">Waiting to start...</div>
          </div>
          <div class="mt-3 grid grid-cols-3 gap-2 text-center text-xs">
            <div>
              <div class="text-gray-400">Time</div>
              <div id="single-pass-time" class="font-bold">--</div>
            </div>
            <div>
              <div class="text-gray-400">Tokens</div>
              <div id="single-pass-tokens" class="font-bold">--</div>
            </div>
            <div>
              <div class="text-gray-400">Calls</div>
              <div id="single-pass-calls" class="font-bold">--</div>
            </div>
          </div>
        </div>
      </div>
      
      <!-- Race Results -->
      <div id="race-results" class="mt-6 p-4 bg-gray-900/50 rounded-lg" style="display: none;">
        <h3 class="text-lg font-semibold mb-3 text-center">üèÜ Race Results</h3>
        <div id="winner-announcement" class="text-center text-2xl font-bold mb-4"></div>
        <div class="grid grid-cols-1 md:grid-cols-3 gap-4 text-center">
          <div>
            <div class="text-gray-400 text-sm">Speed Advantage</div>
            <div id="speed-advantage" class="text-xl font-bold"></div>
          </div>
          <div>
            <div class="text-gray-400 text-sm">Token Efficiency</div>
            <div id="token-efficiency" class="text-xl font-bold"></div>
          </div>
          <div>
            <div class="text-gray-400 text-sm">Cost Savings</div>
            <div id="cost-savings" class="text-xl font-bold"></div>
          </div>
        </div>
      </div>
    </div>

    <!-- Network Effect Simulation -->
    <div class="mt-8 bg-gray-800 p-6 rounded-lg shadow-2xl">
      <h2 class="text-xl font-semibold mb-4 flex items-center">
        üìà Network Effect Simulation
        <button id="simulate-network" class="ml-auto bg-purple-600 hover:bg-purple-700 text-white px-4 py-2 rounded-md text-sm">
          Run Simulation
        </button>
      </h2>
      
      <div class="mb-6">
        <label for="scale-slider" class="block text-sm font-medium text-gray-300 mb-2">
          User Scale: <span id="scale-value">1,000</span> users
        </label>
        <input type="range" id="scale-slider" min="10" max="100000" value="1000" step="10" 
               class="w-full bg-gray-700 rounded-lg appearance-none cursor-pointer">
        <div class="flex justify-between text-xs text-gray-400 mt-1">
          <span>10 users</span>
          <span>100K users</span>
        </div>
      </div>

      <div class="grid grid-cols-1 lg:grid-cols-2 gap-6">
        <!-- Multi-Pass Impact -->
        <div class="bg-red-900/20 border border-red-700 p-4 rounded-lg">
          <h3 class="text-lg font-semibold text-red-300 mb-3">üêå Multi-Pass Impact</h3>
          <div class="space-y-3">
            <div class="flex justify-between">
              <span class="text-sm text-gray-300">Total Tokens:</span>
              <span id="multi-total-tokens" class="font-bold text-red-400">--</span>
            </div>
            <div class="flex justify-between">
              <span class="text-sm text-gray-300">Monthly Cost:</span>
              <span id="multi-monthly-cost" class="font-bold text-red-400">--</span>
            </div>
            <div class="flex justify-between">
              <span class="text-sm text-gray-300">Latency:</span>
              <span id="multi-total-latency" class="font-bold text-red-400">--</span>
            </div>
            <div class="flex justify-between">
              <span class="text-sm text-gray-300">Context Loss:</span>
              <span id="multi-context-loss" class="font-bold text-red-400">--</span>
            </div>
          </div>
        </div>

        <!-- Single-Pass Impact -->
        <div class="bg-green-900/20 border border-green-700 p-4 rounded-lg">
          <h3 class="text-lg font-semibold text-green-300 mb-3">üöÄ Single-Pass Impact</h3>
          <div class="space-y-3">
            <div class="flex justify-between">
              <span class="text-sm text-gray-300">Total Tokens:</span>
              <span id="single-total-tokens" class="font-bold text-green-400">--</span>
            </div>
            <div class="flex justify-between">
              <span class="text-sm text-gray-300">Monthly Cost:</span>
              <span id="single-monthly-cost" class="font-bold text-green-400">--</span>
            </div>
            <div class="flex justify-between">
              <span class="text-sm text-gray-300">Latency:</span>
              <span id="single-total-latency" class="font-bold text-green-400">--</span>
            </div>
            <div class="flex justify-between">
              <span class="text-sm text-gray-300">Context Retention:</span>
              <span id="single-context-retention" class="font-bold text-green-400">--</span>
            </div>
          </div>
        </div>
      </div>

      <!-- Savings Summary -->
      <div id="savings-summary" class="mt-6 p-4 bg-gradient-to-r from-blue-900/30 to-purple-900/30 border border-blue-700 rounded-lg" style="display: none;">
        <h3 class="text-lg font-semibold text-center mb-4">üí∞ Potential Savings</h3>
        <div class="grid grid-cols-1 md:grid-cols-3 gap-4 text-center">
          <div>
            <div class="text-2xl font-bold text-green-400" id="cost-savings-amount">--</div>
            <div class="text-sm text-gray-300">Monthly Savings</div>
          </div>
          <div>
            <div class="text-2xl font-bold text-blue-400" id="speed-improvement">--</div>
            <div class="text-sm text-gray-300">Speed Improvement</div>
          </div>
          <div>
            <div class="text-2xl font-bold text-purple-400" id="efficiency-gain">--</div>
            <div class="text-sm text-gray-300">Efficiency Gain</div>
          </div>
        </div>
      </div>
    </div>

  </div>

  <!-- Pseudo-code templates -->
  <template id="multi-pass-code">
    <pre><code class="language-python">
# Multi-Pass (ReAct)
for attempt in max_retries:
  # 1. First LLM Call
  tool_call = llm.think(prompt)

  # 2. Execute Tool
  result = execute(tool_call)

  if result.is_success():
    # 3. Second LLM Call
    answer = llm.summarize(result)
    return answer
  else:
    # 4. Loop to Retry
    prompt = f"Fix this: {result.error}"
    </code></pre>
  </template>

  <template id="single-pass-code">
    <pre><code class="language-python">
# Single-Pass (SPOC)
while retries < max_retries:
  # 1. Single, Stateful LLM Call
  response = llm.refine(prompt)

  if response.has_tool_call():
    # 2. Execute Tool
    result = execute(response.tool_call)
    # 3. Feed result back into the SAME call
    prompt = f"Result: {result}"
  else:
    # 4. Get final answer
    return response.answer
    </code></pre>
  </template>

  <script>
    document.addEventListener('DOMContentLoaded', () => {
      const form = document.getElementById('prompt-form');
      const log = document.getElementById('log');
      const runButton = document.getElementById('run-button');
      const raceButton = document.getElementById('race-button');
      const modeSelect = document.getElementById('agent-mode');
      const scenarioSelect = document.getElementById('scenario-select');
      const complexitySlider = document.getElementById('complexity-slider');
      const complexityValue = document.getElementById('complexity-value');
      const promptInput = document.getElementById('prompt-input');
      const codeView = document.getElementById('code-view');
      const multiPassTemplate = document.getElementById('multi-pass-code');
      const singlePassTemplate = document.getElementById('single-pass-code');

      // Racing elements
      const racingPanel = document.getElementById('racing-panel');
      const logPanel = document.getElementById('log-panel');
      const stopRaceButton = document.getElementById('stop-race');
      const closeRaceButton = document.getElementById('close-race');
      const raceResults = document.getElementById('race-results');

      // Network simulation elements
      const simulateNetworkButton = document.getElementById('simulate-network');
      const scaleSlider = document.getElementById('scale-slider');
      const scaleValue = document.getElementById('scale-value');
      const savingsSummary = document.getElementById('savings-summary');

      // Execution details elements
      const currentPhaseEl = document.getElementById('current-phase');
      const lastToolEl = document.getElementById('last-tool');
      const contextSizeEl = document.getElementById('context-size');
      const efficiencyRatioEl = document.getElementById('efficiency-ratio');

      const latencyEl = document.getElementById('metric-latency');
      const promptTokensEl = document.getElementById('metric-prompt-tokens');
      const completionTokensEl = document.getElementById('metric-completion-tokens');
      const llmCallsEl = document.getElementById('metric-llm-calls');

      // WebLLM elements
      const modelLoadingPanel = document.getElementById('model-loading-panel');
      const modelStatus = document.getElementById('model-status');
      const modelProgressText = document.getElementById('model-progress-text');
      const modelProgressBar = document.getElementById('model-progress-bar');

      // --- State Management ---
      let currentMode = 'multi_pass';
      let currentScenario = 'sql';
      let webllmEngine = null;
      let modelLoaded = false;

      // Scenario configurations
      const scenarioPrompts = {
        sql: "How many conversions did we get this week?",
        research: "What are the latest developments in climate change research?",
        data_analysis: "Analyze the user engagement trends from our metrics data",
        math_tutor: "Solve the equation: 2x + 5 = 15"
      };

      const scenarioDescriptions = {
        sql: "Query company databases for business metrics",
        research: "Multi-step web search and synthesis",
        data_analysis: "Complex data pipeline analysis",
        math_tutor: "Step-by-step problem solving"
      };

      const updateCodeView = () => {
        codeView.innerHTML = currentMode === 'single_pass'
          ? singlePassTemplate.innerHTML
          : multiPassTemplate.innerHTML;
      };

      const resetMetrics = () => {
        latencyEl.textContent = '0.00s';
        promptTokensEl.textContent = '0';
        completionTokensEl.textContent = '0';
        llmCallsEl.textContent = '0';
        
        // Reset enhanced metrics
        document.getElementById('burn-rate').textContent = '0 tok/s';
        document.getElementById('token-burn-bar').style.width = '0%';
        document.getElementById('total-tokens').textContent = '0 tokens';
        document.getElementById('memory-efficiency').textContent = '100% retained';
        document.getElementById('cost-per-run').textContent = '$0.000';
        document.getElementById('cost-1k').textContent = '$0.00';
        document.getElementById('cost-monthly').textContent = '$0.00';
        
        // Reset execution details
        updateExecutionDetails('Ready', null, null);
        
        // Reset memory blocks
        initializeMemoryBlocks();
      };

      const updateMetrics = (metrics) => {
        if (!metrics) return;
        
        // Update basic metrics
        latencyEl.textContent = `${(metrics.latency || 0).toFixed(2)}s`;
        promptTokensEl.textContent = metrics.prompt_tokens || 0;
        completionTokensEl.textContent = metrics.completion_tokens || 0;
        llmCallsEl.textContent = metrics.llm_calls || 0;
        
        // Update enhanced metrics
        updateEnhancedMetrics(metrics);
      };

      const updateEnhancedMetrics = (metrics) => {
        const totalTokens = (metrics.prompt_tokens || 0) + (metrics.completion_tokens || 0);
        const latency = metrics.latency || 0;
        const burnRate = latency > 0 ? (totalTokens / latency).toFixed(0) : 0;
        
        // Update token burn meter
        document.getElementById('burn-rate').textContent = `${burnRate} tok/s`;
        document.getElementById('total-tokens').textContent = `${totalTokens} tokens`;
        const burnPercentage = Math.min(100, (totalTokens / 500) * 100); // Scale to 500 tokens max
        document.getElementById('token-burn-bar').style.width = `${burnPercentage}%`;
        
        // Update memory visualization
        updateMemoryVisualization(metrics);
        
        // Update cost calculator
        updateCostCalculator(totalTokens);
      };

      const initializeMemoryBlocks = () => {
        const memoryBlocks = document.getElementById('memory-blocks');
        memoryBlocks.innerHTML = '';
        for (let i = 0; i < 10; i++) {
          const block = document.createElement('div');
          block.className = 'bg-gray-600 rounded-sm h-full';
          block.id = `memory-block-${i}`;
          memoryBlocks.appendChild(block);
        }
      };

      const updateMemoryVisualization = (metrics) => {
        const mode = currentMode;
        const llmCalls = metrics.llm_calls || 0;
        
        if (mode === 'single_pass') {
          // Single-pass retains context - show cached blocks
          const cachedBlocks = Math.min(10, llmCalls * 3);
          for (let i = 0; i < 10; i++) {
            const block = document.getElementById(`memory-block-${i}`);
            if (i < cachedBlocks) {
              block.className = 'bg-blue-500 rounded-sm h-full transition-colors duration-500';
            } else {
              block.className = 'bg-gray-600 rounded-sm h-full';
            }
          }
          document.getElementById('memory-efficiency').textContent = `${Math.max(70, 100 - llmCalls * 5)}% retained`;
        } else {
          // Multi-pass loses context - show fresh blocks each time
          for (let i = 0; i < 10; i++) {
            const block = document.getElementById(`memory-block-${i}`);
            if (i < 3) {
              block.className = 'bg-orange-500 rounded-sm h-full transition-colors duration-500';
            } else {
              block.className = 'bg-gray-600 rounded-sm h-full';
            }
          }
          document.getElementById('memory-efficiency').textContent = `${Math.max(20, 50 - llmCalls * 10)}% retained`;
        }
      };

      const updateCostCalculator = (totalTokens) => {
        // Rough cost estimates (GPT-4 pricing: ~$0.03 per 1K tokens)
        const costPerToken = 0.00003;
        const costPerRun = (totalTokens * costPerToken).toFixed(5);
        const cost1K = (totalTokens * costPerToken * 1000).toFixed(2);
        const costMonthly = (totalTokens * costPerToken * 10000).toFixed(2);
        
        document.getElementById('cost-per-run').textContent = `$${costPerRun}`;
        document.getElementById('cost-1k').textContent = `$${cost1K}`;
        document.getElementById('cost-monthly').textContent = `$${costMonthly}`;
      };

      // --- WebLLM Initialization ---
      const initializeWebLLM = async () => {
        try {
          modelLoadingPanel.style.display = 'block';
          runButton.disabled = true;
          
          console.log("üîç Starting WebLLM initialization...");
          
          modelStatus.textContent = "Loading WebLLM library...";
          
          // 1Ô∏è‚É£ Dynamically import WebLLM (fixes race condition)
          const { CreateMLCEngine, prebuiltAppConfig } = await import(
            'https://cdn.jsdelivr.net/npm/@mlc-ai/web-llm@0.2.79/+esm'
          );
          console.log("‚úÖ WebLLM 0.2.79 loaded");

          // 2Ô∏è‚É£ Check WebGPU
          modelStatus.textContent = "Checking WebGPU support...";
          if (!('gpu' in navigator)) {
            throw new Error('WebGPU unavailable on this browser');
          }
          console.log("‚úÖ WebGPU ready");

          // 3Ô∏è‚É£ Verify model in catalogue
          modelStatus.textContent = "Verifying model availability...";
          const selectedModel = "Qwen3-0.6B-q4f16_1-MLC"; // No mlc-ai/ prefix
          const found = prebuiltAppConfig.model_list.some((m) => m.model_id === selectedModel);
          
          if (!found) {
            const qwen3Models = prebuiltAppConfig.model_list
              .filter(m => m.model_id.startsWith("Qwen3"))
              .map(m => m.model_id);
            console.log("Available Qwen3 models:", qwen3Models);
            throw new Error(`${selectedModel} missing from catalogue`);
          }
          console.log(`‚úÖ Model found in catalogue: ${selectedModel}`);

          // 4Ô∏è‚É£ Load the model
          modelStatus.textContent = "Loading model...";
          console.log("üîÑ Creating MLC Engine with model:", selectedModel);
          
          const initProgressCallback = (report) => {
            console.log("üìä Progress:", report);
            const progress = Math.round((report.progress || 0) * 100);
            modelProgressText.textContent = `${progress}%`;
            modelProgressBar.style.width = `${progress}%`;
            modelStatus.textContent = report.text || `Loading model... ${progress}%`;
          };

          webllmEngine = await CreateMLCEngine(selectedModel, { initProgressCallback });
          
          console.log("‚úÖ WebLLM engine created successfully:", webllmEngine);

          modelStatus.textContent = "Model loaded successfully!";
          modelProgressText.textContent = "100%";
          modelProgressBar.style.width = "100%";
          
          setTimeout(() => {
            modelLoadingPanel.style.display = 'none';
            runButton.disabled = false;
            modelLoaded = true;
          }, 1000);

        } catch (error) {
          console.error("‚ùå WebLLM initialization failed:", error);
          console.error("Error details:", {
            message: error.message,
            stack: error.stack,
            name: error.name
          });
          
          modelStatus.textContent = `Error: ${error.message}`;
          modelProgressBar.style.backgroundColor = '#dc2626';
          
          // Show helpful error message without popup
          setTimeout(() => {
            // Update the overlay to show error
            const panel = modelLoadingPanel.querySelector('div');
            panel.innerHTML = `
              <div class="text-center">
                <div class="text-red-400 text-xl mb-4">‚ö†Ô∏è WebLLM Unavailable</div>
                <div class="text-sm text-gray-300 mb-6 text-left">
                  <strong>Most likely cause:</strong> WebGPU not enabled in Chrome<br><br>
                  <strong>Quick fix:</strong><br>
                  1. Go to <code class="bg-gray-700 px-1 rounded">chrome://flags</code><br>
                  2. Search for "webgpu"<br>
                  3. Enable "#enable-unsafe-webgpu"<br>
                  4. Restart Chrome<br><br>
                  <strong>Alternative:</strong> Try Firefox (often enabled by default)
                </div>
                <button onclick="location.reload()" class="bg-blue-600 hover:bg-blue-700 text-white px-4 py-2 rounded mr-3">
                  Retry
                </button>
                <button onclick="enableDemoMode()" class="bg-gray-600 hover:bg-gray-700 text-white px-4 py-2 rounded">
                  View Demo UI
                </button>
              </div>
            `;
            
            // Also update the main UI
            runButton.disabled = true;
            runButton.textContent = 'WebLLM Required';
            runButton.className = runButton.className.replace('bg-blue-600', 'bg-gray-600');
          }, 1000);
        }
      };

      // --- Event Listeners ---
      modeSelect.addEventListener('change', (e) => {
        currentMode = e.target.value;
        updateCodeView();
      });

      scenarioSelect.addEventListener('change', (e) => {
        currentScenario = e.target.value;
        promptInput.value = scenarioPrompts[currentScenario];
      });

      complexitySlider.addEventListener('input', (e) => {
        complexityValue.textContent = e.target.value;
      });

      raceButton.addEventListener('click', (e) => {
        e.preventDefault();
        startRace();
      });

      stopRaceButton.addEventListener('click', () => {
        stopRace();
      });

      closeRaceButton.addEventListener('click', () => {
        racingPanel.style.display = 'none';
        logPanel.style.display = 'block';
      });

      scaleSlider.addEventListener('input', (e) => {
        const value = parseInt(e.target.value);
        scaleValue.textContent = value >= 1000 ? `${(value/1000).toFixed(0)}K` : value.toString();
      });

      simulateNetworkButton.addEventListener('click', () => {
        runNetworkSimulation();
      });

      // Update execution details in real-time
      const updateExecutionDetails = (phase, toolCall, metrics) => {
        currentPhaseEl.textContent = phase || 'Ready';
        lastToolEl.textContent = toolCall ? `${toolCall.name}(${JSON.stringify(toolCall.args).slice(0, 20)}...)` : 'None';
        contextSizeEl.textContent = metrics ? `${(metrics.prompt_tokens || 0)} tokens` : '0 tokens';
        
        if (metrics && metrics.llm_calls > 0) {
          const efficiency = ((metrics.prompt_tokens + metrics.completion_tokens) / metrics.llm_calls).toFixed(0);
          efficiencyRatioEl.textContent = `${efficiency} tok/call`;
        } else {
          efficiencyRatioEl.textContent = '--';
        }
      };

      form.addEventListener('htmx:beforeRequest', (e) => {
        log.innerHTML = '<div class="text-gray-500">Waiting for agent...</div>';
        runButton.disabled = true;
        runButton.textContent = 'Running...';
        resetMetrics();

        // HTMX doesn't have a clean way to send form data as JSON
        // when also using the SSE extension. We will cancel the HTMX
        // request and send our own fetch request.
        e.preventDefault();

        const prompt = document.getElementById('prompt-input').value;
        const scenario = document.getElementById('scenario-select').value;
        
        // Check if we should use WebLLM or server
        if (modelLoaded && webllmEngine) {
          // Use WebLLM for inference
          runWebLLMAgent(prompt, currentMode, scenario);
        } else if (runButton.textContent.includes('Demo Mode')) {
          // Demo mode - show simulated error
          log.innerHTML = '<div class="text-yellow-500">Demo Mode: WebLLM is required for actual inference</div>';
          runButton.disabled = false;
          runButton.textContent = 'Demo Mode - Click to See Error';
          return;
        } else {
          // Fallback to server-based inference
          const payload = {
              prompt: prompt,
              mode: currentMode,
              scenario: scenario
          };
          
          console.log("Using server mode. Sending payload:", JSON.stringify(payload, null, 2));

          // Use the browser's native fetch API to stream the response
          fetch('/solve', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify(payload)
          })
        .then(response => {
            const reader = response.body.getReader();
            const decoder = new TextDecoder();

            // Clear the "Waiting" message
            if (log.firstElementChild && log.firstElementChild.textContent.includes('Waiting')) {
                log.innerHTML = '';
            }

            function push() {
                reader.read().then(({ done, value }) => {
                    if (done) {
                        runButton.disabled = false;
                        runButton.textContent = 'Run Agent';
                        return;
                    }
                    // The response is a stream of "data: {...}" events.
                    // We need to parse them.
                    const chunk = decoder.decode(value);
                    const lines = chunk.split('\n').filter(line => line.trim().startsWith('data:'));
                    for (const line of lines) {
                        const jsonStr = line.replace('data:', '').trim();
                        if (jsonStr) {
                            const data = JSON.parse(jsonStr);
                            handleSseMessage(data);
                        }
                    }
                    push();
                });
            }
            push();
        })
        .catch(err => {
            console.error('Fetch error:', err);
            runButton.disabled = false;
            runButton.textContent = 'Run Agent';
        });
        }
      });

      // --- WebLLM Agent Implementation ---
      const runWebLLMAgent = async (prompt, mode, scenario = 'sql') => {
        console.log(`Running WebLLM agent in ${mode} mode, ${scenario} scenario with prompt: ${prompt}`);
        
        // Clear log and reset UI
        log.innerHTML = '<div class="text-gray-500">Running agent with WebLLM...</div>';
        resetMetrics();
        
        const startTime = performance.now();
        let metrics = { prompt_tokens: 0, completion_tokens: 0, latency: 0, llm_calls: 0 };
        
        try {
          if (mode === 'multi_pass') {
            await runMultiPassWebLLM(prompt, metrics, startTime, scenario);
          } else {
            await runSinglePassWebLLM(prompt, metrics, startTime, scenario);
          }
        } catch (error) {
          console.error('WebLLM agent error:', error);
          handleSseMessage({
            phase: 'error',
            message: `WebLLM error: ${error.message}`,
            metrics: metrics
          });
        } finally {
          runButton.disabled = false;
          runButton.textContent = 'Run Agent';
        }
      };

      const runMultiPassWebLLM = async (prompt, metrics, startTime, scenario = 'sql') => {
        const requestId = `spoc-shot-${Date.now()}`;
        
        // Simulate the multi-pass logic
        while (true) {
          handleSseMessage({ phase: 'propose', metrics });
          
          // First LLM call
          const systemPrompt = `You are an agent designed for a specific demo. Your ONLY purpose is to answer the user's question about "conversions".
1. You MUST use the sql_query tool. It is the only tool available.
2. The sql_query tool takes a single argument: column.
3. The user's question is "How many conversions did we get this week?". You should infer the correct column name from this.
4. Your first action MUST be to call the tool with what you think the column name is. Output a TOOL_CALL in JSON format.
5. After you receive the EXEC_RESULT, if it failed, analyze the 'hint' and call the tool again with the corrected column name.
6. If the result is successful, provide a one-sentence answer summarizing the data.
Example of a tool call:
TOOL_CALL: {"name": "sql_query", "args": {"column": "your_best_guess"}}`;

          const messages = [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: prompt }
          ];

          const completion = await webllmEngine.chat.completions.create({
            messages,
            temperature: 0.0,
            // Note: WebLLM might handle request_id differently
          });

          metrics.llm_calls += 1;
          metrics.prompt_tokens += completion.usage?.prompt_tokens || 0;
          metrics.completion_tokens += completion.usage?.completion_tokens || 0;
          
          const response = completion.choices[0].message.content;
          handleSseMessage({ phase: 'model_response', content: response, metrics });
          
          // Check for tool call
          if (response.includes('TOOL_CALL:')) {
            const toolCallStr = response.split('TOOL_CALL:')[1].trim();
            try {
              const toolCall = JSON.parse(toolCallStr);
              handleSseMessage({ phase: 'execute', call: toolCall, metrics });
              
              // Execute tool (client-side simulation)
              const result = simulateToolCall(toolCall, scenario);
              handleSseMessage({ phase: 'tool_result', result, metrics });
              
              if (result.ok) {
                // Success - make final LLM call for answer
                messages.push({ role: 'assistant', content: response });
                messages.push({ role: 'tool', content: JSON.stringify(result) });
                
                handleSseMessage({ phase: 'propose', metrics });
                const finalCompletion = await webllmEngine.chat.completions.create({
                  messages,
                  temperature: 0.0,
                });
                
                // Don't increment llm_calls for same request_id (simulating KV cache)
                metrics.prompt_tokens += finalCompletion.usage?.prompt_tokens || 0;
                metrics.completion_tokens += finalCompletion.usage?.completion_tokens || 0;
                
                const finalAnswer = finalCompletion.choices[0].message.content;
                metrics.latency = (performance.now() - startTime) / 1000;
                handleSseMessage({ phase: 'success', answer: finalAnswer, metrics });
                return;
              } else {
                // Tool failed, continue loop
                messages.push({ role: 'assistant', content: response });
                messages.push({ role: 'tool', content: JSON.stringify(result) });
                handleSseMessage({ phase: 'failure', message: 'Tool execution failed. Retrying...', metrics });
              }
            } catch (e) {
              handleSseMessage({ phase: 'failure', message: `Invalid tool call: ${e.message}`, metrics });
              break;
            }
          } else {
            metrics.latency = (performance.now() - startTime) / 1000;
            handleSseMessage({ phase: 'success', answer: response, metrics });
            return;
          }
        }
        
        // Continue loop - no max attempts
      };

      const runSinglePassWebLLM = async (prompt, metrics, startTime, scenario = 'sql') => {
        const requestId = `spoc-shot-${Date.now()}`;
        
        // Single-pass logic
        while (true) {
          handleSseMessage({ phase: 'propose', metrics });
          
          const systemPrompt = `You are an agent designed for a specific demo. Your ONLY purpose is to answer the user's question about "conversions".
1. You will be given a TOOL_SIGNATURE for the sql_query tool. It is the only tool you can use.
2. The tool takes a single argument: column.
3. The user's question is "How many conversions did we get this week?". Infer the column name from this question.
4. Your first action MUST be to call the tool. Output a TOOL_CALL in JSON format.
5. If the EXEC_RESULT you receive is a failure, you MUST use the 'hint' to immediately try a new TOOL_CALL with the corrected column name.
6. If the EXEC_RESULT is successful, provide a one-sentence answer summarizing the data.
Example of a tool call:
TOOL_CALL: {"name": "sql_query", "args": {"column": "conversions"}}`;

          const toolSignature = `TOOL_SIGNATURE: {
  "name": "sql_query",
  "description": "Query the company database.",
  "parameters": {
    "type": "object",
    "properties": {
      "column": {
        "type": "string",
        "description": "The column to query, e.g., 'users', 'revenue', 'convs'."
      }
    },
    "required": ["column"]
  }
}`;

          const messages = [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: `${toolSignature}\n\nUser Prompt: ${prompt}` }
          ];

          const completion = await webllmEngine.chat.completions.create({
            messages,
            temperature: 0.0,
          });

          metrics.llm_calls += 1;
          metrics.prompt_tokens += completion.usage?.prompt_tokens || 0;
          metrics.completion_tokens += completion.usage?.completion_tokens || 0;
          
          const response = completion.choices[0].message.content;
          handleSseMessage({ phase: 'model_response', content: response, metrics });
          
          // Check for tool call
          if (response.includes('TOOL_CALL:')) {
            const toolCallStr = response.split('TOOL_CALL:')[1].trim();
            try {
              const toolCall = JSON.parse(toolCallStr);
              handleSseMessage({ phase: 'execute', call: toolCall, metrics });
              
              // Execute tool
              const result = simulateToolCall(toolCall, scenario);
              handleSseMessage({ phase: 'tool_result', result, metrics });
              
              if (result.ok) {
                // Success - generate final answer (simulating continued generation)
                messages.push({ role: 'assistant', content: response });
                messages.push({ role: 'tool', content: JSON.stringify(result) });
                
                const finalCompletion = await webllmEngine.chat.completions.create({
                  messages,
                  temperature: 0.0,
                });
                
                // In true single-pass, this would be continuation, not new call
                metrics.prompt_tokens += finalCompletion.usage?.prompt_tokens || 0;
                metrics.completion_tokens += finalCompletion.usage?.completion_tokens || 0;
                
                const finalAnswer = finalCompletion.choices[0].message.content;
                metrics.latency = (performance.now() - startTime) / 1000;
                handleSseMessage({ phase: 'success', answer: finalAnswer, metrics });
                return;
              } else {
                // Tool failed - show patch phase and continue
                handleSseMessage({ phase: 'patch', message: 'Tool execution failed. Attempting to self-patch.', metrics });
                messages.push({ role: 'assistant', content: response });
                messages.push({ role: 'tool', content: JSON.stringify(result) });
              }
            } catch (e) {
              handleSseMessage({ phase: 'failure', message: `Invalid tool call: ${e.message}`, metrics });
              break;
            }
          } else {
            metrics.latency = (performance.now() - startTime) / 1000;
            handleSseMessage({ phase: 'success', answer: response, metrics });
            return;
          }
        }
        
        // Continue loop - no max attempts
      };

      // Simulate the tool execution client-side
      const simulateToolCall = (toolCall, scenario = 'sql') => {
        const args = toolCall.args || toolCall.arguments || {};
        
        if (scenario === 'sql') {
          const column = args.column;
          if (column === "conversions") {
            return { ok: false, hint: "Did you mean 'convs'?" };
          } else if (column === "convs") {
            return { ok: true, data: 12345 };
          } else {
            return { ok: false, hint: `Column '${column}' not found.` };
          }
        } else if (scenario === 'research') {
          const query = args.query || "";
          if (query.toLowerCase().includes("climate change")) {
            if (!query.toLowerCase().includes("recent")) {
              return { ok: false, hint: "Try searching for 'recent climate change data' for more current results" };
            } else {
              return {
                ok: true,
                data: {
                  results: [
                    { title: "2024 Climate Report", snippet: "Global temperatures rose 1.2¬∞C above pre-industrial levels" },
                    { title: "Arctic Ice Data", snippet: "Sea ice extent decreased by 13% per decade since 1979" }
                  ]
                }
              };
            }
          } else {
            return { ok: false, hint: `No results found for '${query}'. Try more specific terms.` };
          }
        } else if (scenario === 'data_analysis') {
          const dataset = args.dataset;
          const operation = args.operation;
          if (dataset === "user_metrics" && operation === "trend") {
            return {
              ok: true,
              data: {
                trend: "upward",
                growth_rate: "15% monthly",
                key_metric: "Daily Active Users: 50,000"
              }
            };
          } else {
            return { ok: false, hint: `Try 'trend' analysis for 'user_metrics' dataset` };
          }
        } else if (scenario === 'math_tutor') {
          const equation = args.equation;
          const step = args.step;
          if (equation.includes("2x + 5 = 15")) {
            if (step === "simplify") {
              return {
                ok: true,
                data: {
                  result: "2x = 10",
                  explanation: "Subtracted 5 from both sides"
                }
              };
            } else if (step === "calculate") {
              return {
                ok: true,
                data: {
                  result: "x = 5",
                  explanation: "Divided both sides by 2"
                }
              };
            } else {
              return { ok: false, hint: "First 'simplify' the equation by moving constants" };
            }
          } else {
            return { ok: false, hint: `Try breaking down the equation with steps like 'simplify' or 'calculate'` };
          }
        }
        
        return { ok: false, hint: "Unknown tool or scenario" };
      };

      // --- Racing Functionality ---
      let raceControllers = { multiPass: null, singlePass: null };
      let isRacing = false;
      
      const startRace = async () => {
        const prompt = promptInput.value;
        const scenario = scenarioSelect.value;
        
        // Show racing panel, hide log panel
        logPanel.style.display = 'none';
        racingPanel.style.display = 'block';
        raceResults.style.display = 'none';
        
        // Reset race state
        resetRaceState();
        
        // Update UI for racing state
        isRacing = true;
        runButton.disabled = true;
        raceButton.disabled = true;
        stopRaceButton.style.display = 'inline-block';
        
        // Create abort controllers for cancellation
        raceControllers.multiPass = new AbortController();
        raceControllers.singlePass = new AbortController();
        
        try {
          // Start both agents simultaneously
          const multiPassPromise = runRaceAgent(prompt, 'multi_pass', scenario, raceControllers.multiPass.signal);
          const singlePassPromise = runRaceAgent(prompt, 'single_pass', scenario, raceControllers.singlePass.signal);
          
          const results = await Promise.allSettled([multiPassPromise, singlePassPromise]);
          
          // Only show results if race wasn't cancelled
          if (isRacing) {
            showRaceResults(results);
          }
        } catch (error) {
          if (error.name !== 'AbortError') {
            console.error('Race error:', error);
          }
        } finally {
          stopRace();
        }
      };
      
      const stopRace = () => {
        if (isRacing) {
          // Cancel both agents
          if (raceControllers.multiPass) raceControllers.multiPass.abort();
          if (raceControllers.singlePass) raceControllers.singlePass.abort();
          
          // Update status to cancelled
          document.getElementById('multi-pass-status').textContent = 'Cancelled';
          document.getElementById('multi-pass-status').className = document.getElementById('multi-pass-status').className.replace('bg-gray-700', 'bg-yellow-700');
          document.getElementById('single-pass-status').textContent = 'Cancelled';
          document.getElementById('single-pass-status').className = document.getElementById('single-pass-status').className.replace('bg-gray-700', 'bg-yellow-700');
        }
        
        // Reset UI state
        isRacing = false;
        runButton.disabled = false;
        raceButton.disabled = false;
        stopRaceButton.style.display = 'none';
        
        // Reset controllers
        raceControllers = { multiPass: null, singlePass: null };
      };

      const resetRaceState = () => {
        // Reset multi-pass
        document.getElementById('multi-pass-status').textContent = 'Starting...';
        document.getElementById('multi-pass-progress').style.width = '0%';
        document.getElementById('multi-pass-progress-text').textContent = '0%';
        document.getElementById('multi-pass-log').innerHTML = '<div class="text-gray-500">Starting...</div>';
        document.getElementById('multi-pass-time').textContent = '--';
        document.getElementById('multi-pass-tokens').textContent = '--';
        document.getElementById('multi-pass-calls').textContent = '--';
        
        // Reset single-pass
        document.getElementById('single-pass-status').textContent = 'Starting...';
        document.getElementById('single-pass-progress').style.width = '0%';
        document.getElementById('single-pass-progress-text').textContent = '0%';
        document.getElementById('single-pass-log').innerHTML = '<div class="text-gray-500">Starting...</div>';
        document.getElementById('single-pass-time').textContent = '--';
        document.getElementById('single-pass-tokens').textContent = '--';
        document.getElementById('single-pass-calls').textContent = '--';
      };

      const runRaceAgent = async (prompt, mode, scenario, abortSignal) => {
        const startTime = performance.now();
        let metrics = { prompt_tokens: 0, completion_tokens: 0, latency: 0, llm_calls: 0 };
        const prefix = mode === 'multi_pass' ? 'multi-pass' : 'single-pass';
        let attemptCount = 0;
        let isComplete = false;
        
        const statusEl = document.getElementById(`${prefix}-status`);
        const progressEl = document.getElementById(`${prefix}-progress`);
        const progressTextEl = document.getElementById(`${prefix}-progress-text`);
        const logEl = document.getElementById(`${prefix}-log`);
        const timeEl = document.getElementById(`${prefix}-time`);
        const tokensEl = document.getElementById(`${prefix}-tokens`);
        const callsEl = document.getElementById(`${prefix}-calls`);
        
        const updateRaceUI = (phase, data = {}) => {
          // Check if cancelled
          if (abortSignal?.aborted) {
            throw new Error('Race cancelled');
          }
          
          // Better progress calculation based on actual progress
          let progress = 0;
          if (phase === 'success') {
            progress = 100;
            isComplete = true;
          } else if (phase === 'execute' || phase === 'tool_result') {
            // Each attempt represents progress towards solution
            progress = Math.min(80, attemptCount * 15 + 10);
          } else if (phase === 'propose') {
            progress = Math.min(70, attemptCount * 15);
          } else if (phase === 'patch') {
            progress = Math.min(85, attemptCount * 15 + 5);
          }
          
          progressEl.style.width = `${progress}%`;
          progressTextEl.textContent = `${progress}%`;
          
          const elapsed = (performance.now() - startTime) / 1000;
          timeEl.textContent = `${elapsed.toFixed(1)}s`;
          tokensEl.textContent = metrics.prompt_tokens + metrics.completion_tokens;
          callsEl.textContent = metrics.llm_calls;
          
          // Add log entry
          const entry = document.createElement('div');
          entry.className = 'mb-1 text-xs';
          const timestamp = `[${elapsed.toFixed(1)}s]`;
          
          switch (phase) {
            case 'propose':
              entry.innerHTML = `${timestamp} üß† Thinking...`;
              statusEl.textContent = 'Thinking';
              break;
            case 'execute':
              const toolArgs = JSON.stringify(data.call?.args || {});
              entry.innerHTML = `${timestamp} ‚öôÔ∏è <strong>TOOL CALL:</strong> ${data.call?.name}(${toolArgs})`;
              statusEl.textContent = 'Executing';
              break;
            case 'tool_result':
              const resultClass = data.result?.ok ? 'text-green-300' : 'text-red-300';
              const resultJson = JSON.stringify(data.result);
              entry.innerHTML = `${timestamp} <span class="${resultClass}">üì¶ <strong>TOOL RESPONSE:</strong> ${resultJson}</span>`;
              break;
            case 'patch':
              entry.innerHTML = `${timestamp} üîß Self-correcting...`;
              statusEl.textContent = 'Patching';
              break;
            case 'success':
              entry.innerHTML = `${timestamp} ‚úÖ Complete!`;
              statusEl.textContent = 'Complete';
              statusEl.className = statusEl.className.replace('bg-gray-700', 'bg-green-700');
              break;
            case 'error':
              entry.innerHTML = `${timestamp} ‚ùå Error: ${data.message}`;
              statusEl.textContent = 'Error';
              statusEl.className = statusEl.className.replace('bg-gray-700', 'bg-red-700');
              break;
          }
          
          logEl.appendChild(entry);
          logEl.scrollTop = logEl.scrollHeight;
        };
        
        try {
          // Simulate the agent execution
          if (mode === 'multi_pass') {
            await simulateMultiPassRace(prompt, scenario, metrics, updateRaceUI, abortSignal, () => attemptCount++);
          } else {
            await simulateSinglePassRace(prompt, scenario, metrics, updateRaceUI, abortSignal, () => attemptCount++);
          }
          
          metrics.latency = (performance.now() - startTime) / 1000;
          return { mode, metrics, success: true };
        } catch (error) {
          if (error.message === 'Race cancelled' || abortSignal?.aborted) {
            return { mode, metrics, success: false, cancelled: true };
          }
          updateRaceUI('error', { message: error.message });
          return { mode, metrics, success: false, error };
        }
      };

      const simulateMultiPassRace = async (prompt, scenario, metrics, updateUI, abortSignal, incrementAttempt) => {
        let attemptNumber = 0;
        let lastHint = null;
        
        while (true) {
          if (abortSignal?.aborted) throw new Error('Race cancelled');
          
          attemptNumber++;
          incrementAttempt();
          updateUI('propose');
          await sleep(800 + Math.random() * 400); // Variable delay
          
          if (abortSignal?.aborted) throw new Error('Race cancelled');
          
          metrics.llm_calls += 1;
          metrics.prompt_tokens += 150;
          metrics.completion_tokens += 50;
          
          // Learn from previous failures
          const toolCall = { 
            name: getToolForScenario(scenario), 
            args: getSmartArgsForScenario(scenario, attemptNumber, lastHint) 
          };
          updateUI('execute', { call: toolCall });
          await sleep(500 + Math.random() * 300);
          
          if (abortSignal?.aborted) throw new Error('Race cancelled');
          
          const result = simulateToolCall(toolCall, scenario);
          updateUI('tool_result', { result });
          
          // Save hint for next attempt
          if (!result.ok && result.hint) {
            lastHint = result.hint;
          }
          
          if (result.ok) {
            updateUI('propose');
            await sleep(600 + Math.random() * 400);
            
            if (abortSignal?.aborted) throw new Error('Race cancelled');
            
            metrics.llm_calls += 1; // Separate final call
            metrics.prompt_tokens += 100;
            metrics.completion_tokens += 30;
            updateUI('success');
            return;
          } else {
            await sleep(300);
          }
        }
      };

      const simulateSinglePassRace = async (prompt, scenario, metrics, updateUI, abortSignal, incrementAttempt) => {
        let attemptNumber = 0;
        let lastHint = null;
        
        while (true) {
          if (abortSignal?.aborted) throw new Error('Race cancelled');
          
          attemptNumber++;
          incrementAttempt();
          updateUI('propose');
          await sleep(600 + Math.random() * 200); // Faster due to KV cache
          
          if (abortSignal?.aborted) throw new Error('Race cancelled');
          
          metrics.llm_calls += 1;
          metrics.prompt_tokens += 120; // Lower due to context reuse
          metrics.completion_tokens += 45;
          
          // Learn from previous failures
          const toolCall = { 
            name: getToolForScenario(scenario), 
            args: getSmartArgsForScenario(scenario, attemptNumber, lastHint) 
          };
          updateUI('execute', { call: toolCall });
          await sleep(400 + Math.random() * 200);
          
          if (abortSignal?.aborted) throw new Error('Race cancelled');
          
          const result = simulateToolCall(toolCall, scenario);
          updateUI('tool_result', { result });
          
          // Save hint for next attempt
          if (!result.ok && result.hint) {
            lastHint = result.hint;
          }
          
          if (result.ok) {
            // Single-pass continues in same context
            await sleep(200);
            
            if (abortSignal?.aborted) throw new Error('Race cancelled');
            
            metrics.completion_tokens += 25; // Less tokens for final answer
            updateUI('success');
            return;
          } else {
            updateUI('patch');
            await sleep(100); // Faster recovery
          }
        }
      };

      const getToolForScenario = (scenario) => {
        const tools = {
          sql: 'sql_query',
          research: 'web_search',
          data_analysis: 'analyze_data',
          math_tutor: 'solve_equation'
        };
        return tools[scenario] || 'sql_query';
      };

      const getArgsForScenario = (scenario) => {
        const args = {
          sql: { column: 'conversions' },
          research: { query: 'climate change' },
          data_analysis: { dataset: 'user_metrics', operation: 'summary' },
          math_tutor: { equation: '2x + 5 = 15', step: 'isolate' }
        };
        return args[scenario] || { column: 'conversions' };
      };

      // Smart version that learns from hints
      const getSmartArgsForScenario = (scenario, attemptNumber, lastHint) => {
        if (scenario === 'sql') {
          if (attemptNumber === 1) {
            return { column: 'conversions' }; // First attempt - will fail
          } else if (lastHint && lastHint.includes("'convs'")) {
            return { column: 'convs' }; // Learn from hint
          } else {
            return { column: 'conversions' }; // Fallback
          }
        } else if (scenario === 'research') {
          if (attemptNumber === 1) {
            return { query: 'climate change' }; // First attempt - will fail
          } else if (lastHint && lastHint.includes('recent')) {
            return { query: 'recent climate change data' }; // Learn from hint
          } else {
            return { query: 'climate change' }; // Fallback
          }
        } else if (scenario === 'data_analysis') {
          if (attemptNumber === 1) {
            return { dataset: 'user_metrics', operation: 'summary' }; // First attempt - will fail
          } else if (lastHint && lastHint.includes('trend')) {
            return { dataset: 'user_metrics', operation: 'trend' }; // Learn from hint
          } else {
            return { dataset: 'user_metrics', operation: 'summary' }; // Fallback
          }
        } else if (scenario === 'math_tutor') {
          if (attemptNumber === 1) {
            return { equation: '2x + 5 = 15', step: 'isolate' }; // First attempt - will fail
          } else if (lastHint && lastHint.includes('simplify')) {
            return { equation: '2x + 5 = 15', step: 'simplify' }; // Learn from hint
          } else {
            return { equation: '2x + 5 = 15', step: 'isolate' }; // Fallback
          }
        }
        
        // Default fallback
        return getArgsForScenario(scenario);
      };

      const showRaceResults = (results) => {
        raceResults.style.display = 'block';
        
        const multiResult = results[0].status === 'fulfilled' ? results[0].value : null;
        const singleResult = results[1].status === 'fulfilled' ? results[1].value : null;
        
        if (multiResult && singleResult) {
          const speedAdvantage = ((multiResult.metrics.latency - singleResult.metrics.latency) / multiResult.metrics.latency * 100).toFixed(1);
          const tokenSavings = ((multiResult.metrics.prompt_tokens + multiResult.metrics.completion_tokens) - (singleResult.metrics.prompt_tokens + singleResult.metrics.completion_tokens));
          const costSavings = (tokenSavings * 0.00001 * 1000).toFixed(2); // Rough cost estimate
          
          document.getElementById('winner-announcement').innerHTML = 
            singleResult.metrics.latency < multiResult.metrics.latency 
              ? 'üöÄ Single-Pass Wins!' 
              : 'üêå Multi-Pass Wins!';
          
          document.getElementById('speed-advantage').textContent = `${speedAdvantage}% faster`;
          document.getElementById('token-efficiency').textContent = `${tokenSavings} tokens saved`;
          document.getElementById('cost-savings').textContent = `$${costSavings} saved per 1K runs`;
        }
      };

      const sleep = (ms) => new Promise(resolve => setTimeout(resolve, ms));

      // --- Network Effect Simulation ---
      const runNetworkSimulation = () => {
        const userCount = parseInt(scaleSlider.value);
        const scenario = scenarioSelect.value;
        
        // Disable button during simulation
        simulateNetworkButton.disabled = true;
        simulateNetworkButton.textContent = 'Simulating...';
        
        // Simulate the calculations
        setTimeout(() => {
          const results = calculateNetworkEffect(userCount, scenario);
          displayNetworkResults(results);
          
          simulateNetworkButton.disabled = false;
          simulateNetworkButton.textContent = 'Run Simulation';
          savingsSummary.style.display = 'block';
        }, 800);
      };

      const calculateNetworkEffect = (userCount, scenario) => {
        // Base metrics per run (from our simulations)
        const baseMetrics = {
          sql: { multiTokens: 200, singleTokens: 165, multiLatency: 2.5, singleLatency: 1.8 },
          research: { multiTokens: 350, singleTokens: 280, multiLatency: 4.2, singleLatency: 2.9 },
          data_analysis: { multiTokens: 280, singleTokens: 220, multiLatency: 3.1, singleLatency: 2.2 },
          math_tutor: { multiTokens: 180, singleTokens: 150, multiLatency: 2.0, singleLatency: 1.5 }
        };

        const metrics = baseMetrics[scenario] || baseMetrics.sql;
        
        // Assume each user runs 5 queries per day, 30 days per month
        const runsPerMonth = userCount * 5 * 30;
        
        // Calculate multi-pass totals
        const multiTotalTokens = runsPerMonth * metrics.multiTokens;
        const multiTotalLatency = runsPerMonth * metrics.multiLatency;
        const multiMonthlyCost = multiTotalTokens * 0.00003; // $0.03 per 1K tokens
        const multiContextLoss = Math.min(95, 60 + (userCount / 1000) * 10); // Increases with scale
        
        // Calculate single-pass totals
        const singleTotalTokens = runsPerMonth * metrics.singleTokens;
        const singleTotalLatency = runsPerMonth * metrics.singleLatency;
        const singleMonthlyCost = singleTotalTokens * 0.00003;
        const singleContextRetention = Math.max(75, 90 - (userCount / 10000) * 5); // Decreases slightly with scale
        
        // Calculate savings
        const costSavings = multiMonthlyCost - singleMonthlyCost;
        const speedImprovement = ((multiTotalLatency - singleTotalLatency) / multiTotalLatency * 100);
        const efficiencyGain = ((multiTotalTokens - singleTotalTokens) / multiTotalTokens * 100);
        
        return {
          userCount,
          multi: {
            totalTokens: multiTotalTokens,
            monthlyCost: multiMonthlyCost,
            totalLatency: multiTotalLatency,
            contextLoss: multiContextLoss
          },
          single: {
            totalTokens: singleTotalTokens,
            monthlyCost: singleMonthlyCost,
            totalLatency: singleTotalLatency,
            contextRetention: singleContextRetention
          },
          savings: {
            costSavings,
            speedImprovement,
            efficiencyGain
          }
        };
      };

      const displayNetworkResults = (results) => {
        // Format large numbers
        const formatNumber = (num) => {
          if (num >= 1000000) return `${(num/1000000).toFixed(1)}M`;
          if (num >= 1000) return `${(num/1000).toFixed(1)}K`;
          return num.toFixed(0);
        };

        const formatCost = (cost) => {
          if (cost >= 1000) return `$${(cost/1000).toFixed(1)}K`;
          return `$${cost.toFixed(2)}`;
        };

        const formatTime = (seconds) => {
          const hours = seconds / 3600;
          if (hours >= 24) return `${(hours/24).toFixed(1)} days`;
          if (hours >= 1) return `${hours.toFixed(1)} hrs`;
          return `${(seconds/60).toFixed(0)} mins`;
        };

        // Multi-pass results
        document.getElementById('multi-total-tokens').textContent = formatNumber(results.multi.totalTokens);
        document.getElementById('multi-monthly-cost').textContent = formatCost(results.multi.monthlyCost);
        document.getElementById('multi-total-latency').textContent = formatTime(results.multi.totalLatency);
        document.getElementById('multi-context-loss').textContent = `${results.multi.contextLoss.toFixed(0)}%`;

        // Single-pass results
        document.getElementById('single-total-tokens').textContent = formatNumber(results.single.totalTokens);
        document.getElementById('single-monthly-cost').textContent = formatCost(results.single.monthlyCost);
        document.getElementById('single-total-latency').textContent = formatTime(results.single.totalLatency);
        document.getElementById('single-context-retention').textContent = `${results.single.contextRetention.toFixed(0)}%`;

        // Savings summary
        document.getElementById('cost-savings-amount').textContent = formatCost(results.savings.costSavings);
        document.getElementById('speed-improvement').textContent = `${results.savings.speedImprovement.toFixed(1)}%`;
        document.getElementById('efficiency-gain').textContent = `${results.savings.efficiencyGain.toFixed(1)}%`;
      };


      function handleSseMessage(data) {
        const entry = document.createElement('div');
        entry.className = 'log-entry p-2 rounded-md flex items-start';

        const now = new Date();
        const timestamp = `[${now.getHours().toString().padStart(2, '0')}:${now.getMinutes().toString().padStart(2, '0')}:${now.getSeconds().toString().padStart(2, '0')}]`;

        const ICONS = {
          propose: 'üß†',
          execute: '‚öôÔ∏è',
          failure: '‚ùå',
          patch: 'üîß',
          success: '‚úÖ',
          tool_result: 'üì¶',
          model_response: 'üí¨',
          error: 'üî•'
        };

        let icon = ICONS[data.phase] || '‚û°Ô∏è';
        let content = '';
        let colorClass = 'bg-gray-700/50';

        switch (data.phase) {
          case 'propose':
            content = `<span class="font-bold text-cyan-400">PROPOSE</span>: Agent is thinking...`;
            updateExecutionDetails('Thinking', null, data.metrics);
            break;
          case 'model_response':
            content = `<span class="font-bold text-gray-400">MODEL</span>: <pre class="inline-block whitespace-pre-wrap">${data.content}</pre>`;
            updateExecutionDetails('Generated Response', null, data.metrics);
            break;
          case 'execute':
            const attemptInfo = data.debug ? ` (Attempt ${data.debug.attempt})` : '';
            content = `<span class="font-bold text-purple-400">EXECUTE${attemptInfo}</span>: Calling tool <code class="text-white bg-gray-800 px-1 rounded">${data.call.name}</code><br>
                       <span class="text-gray-400">Args:</span> <code class="text-white bg-gray-800 px-2 py-1 rounded block mt-1">${JSON.stringify(data.call.args, null, 2)}</code>`;
            updateExecutionDetails('Executing Tool', data.call, data.metrics);
            break;
          case 'tool_result':
            const resultClass = data.result.ok ? 'text-green-400' : 'text-red-400';
            const verifiedInfo = data.debug ? ` | Verified: ${data.debug.verified}` : '';
            content = `<span class="font-bold ${resultClass}">RESULT</span>: <span class="text-gray-400">Status: ${data.result.ok ? 'SUCCESS' : 'FAILED'}${verifiedInfo}</span><br>
                       <code class="text-white bg-gray-800 px-2 py-1 rounded block mt-1">${JSON.stringify(data.result, null, 2)}</code>`;
            updateExecutionDetails(data.result.ok ? 'Tool Success' : 'Tool Failed', null, data.metrics);
            break;
          case 'failure':
             content = `<span class="font-bold text-red-500">FAILURE</span>: ${data.message}`;
             colorClass = 'bg-red-900/30';
             updateExecutionDetails('Failed', null, data.metrics);
             break;
          case 'patch':
            content = `<span class="font-bold text-yellow-400">PATCH</span>: Tool failed. Attempting to self-correct...`;
            colorClass = 'bg-yellow-900/30';
            updateExecutionDetails('Self-Correcting', null, data.metrics);
            break;
          case 'success':
            content = `<span class="font-bold text-green-400">SUCCESS</span>: <pre class="inline-block whitespace-pre-wrap">${data.answer}</pre>`;
            colorClass = 'bg-green-900/30';
            updateExecutionDetails('Completed', null, data.metrics);
            break;
          case 'error':
            content = `<span class="font-bold text-red-500">ERROR</span>: ${data.message}`;
            colorClass = 'bg-red-900/50 border border-red-700';
            updateExecutionDetails('Error', null, data.metrics);
            break;
        }
        
        entry.className += ` ${colorClass}`;
        entry.innerHTML = `<span class="mr-2 text-gray-500">${timestamp}</span><span class="mr-3">${icon}</span> <div class="flex-1">${content}</div>`;
        log.appendChild(entry);
        log.scrollTop = log.scrollHeight;

        updateMetrics(data.metrics);
      }

      // Remove the now-unused global SSE listener
      // document.body.removeEventListener('htmx:sseMessage', ...);

      form.addEventListener('htmx:afterRequest', () => {
        runButton.disabled = false;
        runButton.textContent = 'Run Agent';
      });

      document.body.addEventListener('htmx:sseMessage', (event) => {
        if (log.firstElementChild && log.firstElementChild.textContent.includes('Waiting')) {
            log.innerHTML = ''; // Clear "Waiting" message
        }
        
        const data = JSON.parse(event.detail.data);
        const entry = document.createElement('div');
        entry.className = 'log-entry p-2 rounded-md flex items-start';

        const ICONS = {
          propose: 'üß†',
          execute: '‚öôÔ∏è',
          failure: '‚ùå',
          patch: 'üîß',
          success: '‚úÖ',
          tool_result: 'üì¶',
          model_response: 'üí¨',
          error: 'üî•'
        };

        let icon = ICONS[data.phase] || '‚û°Ô∏è';
        let content = '';
        let colorClass = 'bg-gray-700/50';

        switch (data.phase) {
          case 'propose':
            content = `<span class="font-bold text-cyan-400">PROPOSE</span>: Agent is thinking...`;
            break;
          case 'model_response':
            content = `<span class="font-bold text-gray-400">MODEL</span>: <pre class="inline-block whitespace-pre-wrap">${data.content}</pre>`;
            break;
          case 'execute':
            const attemptInfo = data.debug ? ` (Attempt ${data.debug.attempt})` : '';
            content = `<span class="font-bold text-purple-400">EXECUTE${attemptInfo}</span>: Calling tool <code class="text-white bg-gray-800 px-1 rounded">${data.call.name}</code><br>
                       <span class="text-gray-400">Args:</span> <code class="text-white bg-gray-800 px-2 py-1 rounded block mt-1">${JSON.stringify(data.call.args, null, 2)}</code>`;
            break;
          case 'tool_result':
            const resultClass = data.result.ok ? 'text-green-400' : 'text-red-400';
            const verifiedInfo = data.debug ? ` | Verified: ${data.debug.verified}` : '';
            content = `<span class="font-bold ${resultClass}">RESULT</span>: <span class="text-gray-400">Status: ${data.result.ok ? 'SUCCESS' : 'FAILED'}${verifiedInfo}</span><br>
                       <code class="text-white bg-gray-800 px-2 py-1 rounded block mt-1">${JSON.stringify(data.result, null, 2)}</code>`;
            break;
          case 'failure':
             content = `<span class="font-bold text-red-500">FAILURE</span>: ${data.message}`;
             colorClass = 'bg-red-900/30';
             break;
          case 'patch':
            content = `<span class="font-bold text-yellow-400">PATCH</span>: Tool failed. Attempting to self-correct...`;
            colorClass = 'bg-yellow-900/30';
            break;
          case 'success':
            content = `<span class="font-bold text-green-400">SUCCESS</span>: <pre class="inline-block whitespace-pre-wrap">${data.answer}</pre>`;
            colorClass = 'bg-green-900/30';
            break;
          case 'error':
            content = `<span class="font-bold text-red-500">ERROR</span>: ${data.message}`;
            colorClass = 'bg-red-900/50 border border-red-700';
            break;
        }
        
        entry.className += ` ${colorClass}`;
        entry.innerHTML = `<span class="mr-3">${icon}</span> <div class="flex-1">${content}</div>`;
        log.appendChild(entry);
        log.scrollTop = log.scrollHeight;

        updateMetrics(data.metrics);
      });

      // --- App Initialization ---
      const initializeApp = async () => {
        try {
          // Check server configuration
          const configResponse = await fetch('/api/config');
          const config = await configResponse.json();
          
          console.log('Server config:', config);
          
          if (config.server_available) {
            // Server mode available - initialize WebLLM as enhancement
            console.log('Server available, initializing WebLLM as enhancement...');
            initializeWebLLM();
          } else {
            // WebLLM required mode
            console.log('Server not available, WebLLM required...');
            modelStatus.textContent = "Server not available. WebLLM required for inference.";
            initializeWebLLM();
          }
        } catch (error) {
          console.error('Failed to check server config:', error);
          // Assume WebLLM required
          initializeWebLLM();
        }
      };

      // --- Demo Mode (when WebLLM fails) ---
      window.enableDemoMode = () => {
        modelLoadingPanel.style.display = 'none';
        
        // Show demo notice
        const demoNotice = document.createElement('div');
        demoNotice.className = 'mb-6 bg-yellow-900/30 border border-yellow-700 p-4 rounded-lg text-center';
        demoNotice.innerHTML = `
          <div class="text-yellow-400 font-semibold mb-2">üìñ Demo UI Mode</div>
          <div class="text-sm text-gray-300">
            WebLLM is unavailable, but you can explore the interface design.<br>
            For full functionality, try a WebGPU-compatible browser.
          </div>
        `;
        document.querySelector('.w-full.max-w-7xl').insertBefore(demoNotice, document.querySelector('.grid'));
        
        // Enable button for demo purposes (shows error when clicked)
        runButton.disabled = false;
        runButton.textContent = 'Demo Mode - Click to See Error';
        runButton.className = runButton.className.replace('bg-gray-600', 'bg-yellow-600');
      };

      // --- Initial Setup ---
      updateCodeView();
      initializeMemoryBlocks();
      
      // Check server configuration and initialize accordingly
      initializeApp();
    });
  </script>

</body>
</html>
